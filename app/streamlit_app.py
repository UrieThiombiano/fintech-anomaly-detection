"""
Application Streamlit principale pour la d√©tection d'anomalies fintech.
"""
import sys
from pathlib import Path

# Ajouter le r√©pertoire src au path
ROOT_DIR = Path(__file__).resolve().parents[1]
if str(ROOT_DIR) not in sys.path:
    sys.path.append(str(ROOT_DIR))

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from src.data.loader import load_uploaded_file
from src.features.user_features import build_user_features, get_user_feature_description
from src.features.transaction_features import build_transaction_features, get_transaction_feature_description
from src.models.pca import compute_pca, get_pca_summary, get_top_loadings
from src.models.clustering import (
    compute_elbow_curve, compute_silhouette_scores, 
    train_kmeans, get_cluster_profiles, suggest_optimal_k
)
from src.models.anomaly_detection import (
    train_isolation_forest, analyze_anomalies, 
    get_anomaly_statistics, suggest_contamination
)
from src.xai.shap_explainer import (
    compute_shap_for_isolation_forest, get_top_shap_features,
    generate_shap_summary, explain_anomaly_in_french
)
from src.config import RANDOM_STATE


# --------- Configuration de l'application --------- #

st.set_page_config(
    page_title="Fintech Anomaly Detection",
    page_icon="üí∞",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #3B82F6;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .info-box {
        background-color: #F0F9FF;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin-bottom: 1rem;
    }
    .warning-box {
        background-color: #FEF3C7;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #F59E0B;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #F8FAFC;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #E2E8F0;
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)


# --------- Fonctions de cache --------- #

@st.cache_data(show_spinner="Chargement des donn√©es...")
def load_and_prepare_data(uploaded_file):
    """Charge et pr√©pare les donn√©es depuis le fichier upload√©."""
    df_raw = load_uploaded_file(uploaded_file)
    user_features = build_user_features(df_raw)
    tx_features = build_transaction_features(df_raw)
    return df_raw, user_features, tx_features


@st.cache_data(show_spinner="Calcul de la PCA...")
def compute_pca_cached(user_features, n_components):
    """Calcule la PCA avec cache."""
    return compute_pca(user_features, n_components=n_components)


@st.cache_data(show_spinner="Calcul du coude KMeans...")
def compute_elbow_cached(user_features, k_min, k_max):
    """Calcule la courbe du coude avec cache."""
    return compute_elbow_curve(user_features, k_min, k_max)


@st.cache_data(show_spinner="Calcul des scores silhouette...")
def compute_silhouette_cached(user_features, k_min, k_max):
    """Calcule les scores silhouette avec cache."""
    return compute_silhouette_scores(user_features, k_min, k_max)


@st.cache_data(show_spinner="Entra√Ænement KMeans...")
def train_kmeans_cached(user_features, n_clusters):
    """Entra√Æne KMeans avec cache."""
    return train_kmeans(user_features, n_clusters=n_clusters)


@st.cache_data(show_spinner="Entra√Ænement Isolation Forest...")
def train_iforest_cached(tx_features, contamination):
    """Entra√Æne Isolation Forest avec cache."""
    return train_isolation_forest(tx_features, contamination=contamination)


@st.cache_data(show_spinner="Calcul SHAP...")
def compute_shap_cached(iforest, scaler, tx_features, sample_size):
    """Calcule SHAP avec cache."""
    return compute_shap_for_isolation_forest(iforest, scaler, tx_features, sample_size)


# --------- Pages --------- #

def page_objectifs():
    """Page d'accueil avec les objectifs du projet."""
    st.markdown('<h1 class="main-header">üí∞ D√©tection d\'Anomalies Fintech</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h3>üéØ Objectifs du projet</h3>
    <p>Cette application analyse des transactions d'un portefeuille digital pour :</p>
    <ul>
    <li><b>Segmenter les utilisateurs</b> selon leurs comportements de d√©pense</li>
    <li><b>D√©tecter des transactions anormales</b> (montants atypiques, abus de cashback, comportements suspects)</li>
    <li><b>Expliquer ces anomalies</b> avec des m√©thodes d'explicabilit√© (XAI)</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
        <h4>üîç ACP</h4>
        <p>R√©duction de dimension et analyse des relations entre variables</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
        <h4>üìä KMeans</h4>
        <p>Segmentation non supervis√©e des utilisateurs</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
        <h4>üå≤ Isolation Forest</h4>
        <p>D√©tection d'anomalies sans labels</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("""
    ## üìà M√©thodologie
    
    ### 1. Analyse en Composantes Principales (ACP)
    - **1er principe** : Repr√©senter les utilisateurs dans un espace r√©duit
    - **2√®me principe** : Analyser les relations entre variables via les corr√©lations
    
    ### 2. Segmentation par KMeans
    - Regroupement des utilisateurs en clusters homog√®nes
    - Choix du nombre optimal de clusters via m√©thode du coude et silhouette
    
    ### 3. D√©tection d'Anomalies avec Isolation Forest
    - Algorithmes d'arbres pour isoler les points atypiques
    - Pas besoin de donn√©es labellis√©es
    
    ### 4. Explications avec SHAP
    - D√©composition feature par feature des d√©cisions du mod√®le
    - Compr√©hension des raisons d'une pr√©diction d'anomalie
    
    ## üöÄ Comment utiliser cette application
    
    1. **Importez vos donn√©es** via le menu lat√©ral
    2. **Explorez les donn√©es** dans l'onglet Exploration
    3. **Analysez les utilisateurs** avec ACP et KMeans
    4. **D√©tectez les anomalies** transactionnelles
    5. **Comprenez les r√©sultats** avec SHAP
    
    Toutes les √©tapes sont interactives et param√©trables !
    """)


def page_eda(df_raw, user_features, tx_features):
    """Page d'exploration des donn√©es."""
    st.markdown('<h1 class="main-header">üîç Exploration des Donn√©es</h1>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["Donn√©es Brutes", "Features Utilisateur", "Features Transaction"])
    
    with tab1:
        st.markdown('<h2 class="sub-header">Donn√©es Brutes des Transactions</h2>', unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Nombre de transactions", df_raw.shape[0])
        with col2:
            st.metric("Nombre de colonnes", df_raw.shape[1])
        with col3:
            st.metric("Utilisateurs uniques", df_raw['user_id'].nunique())
        
        st.subheader("Aper√ßu des donn√©es")
        st.dataframe(df_raw.head(10), use_container_width=True)
        
        st.subheader("Types de donn√©es")
        dtype_df = pd.DataFrame({
            'Colonne': df_raw.columns,
            'Type': df_raw.dtypes.astype(str),
            'Valeurs uniques': [df_raw[col].nunique() for col in df_raw.columns],
            'Valeurs manquantes': df_raw.isna().sum().values
        })
        st.dataframe(dtype_df, use_container_width=True)
        
        st.subheader("Statistiques descriptives")
        numeric_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            st.dataframe(df_raw[numeric_cols].describe().round(2), use_container_width=True)
        
        # Visualisations
        st.subheader("Distributions")
        col1, col2 = st.columns(2)
        
        with col1:
            if 'product_amount' in df_raw.columns:
                fig = px.histogram(df_raw, x='product_amount', nbins=50,
                                  title="Distribution des montants")
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            if 'cashback' in df_raw.columns:
                fig = px.histogram(df_raw, x='cashback', nbins=50,
                                  title="Distribution du cashback")
                st.plotly_chart(fig, use_container_width=True)
        
        if 'product_category' in df_raw.columns:
            fig = px.bar(df_raw['product_category'].value_counts().head(10),
                        title="Top 10 cat√©gories de produits")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.markdown('<h2 class="sub-header">Features Utilisateur</h2>', unsafe_allow_html=True)
        
        st.metric("Nombre d'utilisateurs", user_features.shape[0])
        st.metric("Nombre de features", user_features.shape[1])
        
        st.subheader("Aper√ßu des features")
        st.dataframe(user_features.head(10), use_container_width=True)
        
        st.subheader("Description des features")
        feature_desc = get_user_feature_description()
        desc_df = pd.DataFrame({
            'Feature': list(feature_desc.keys()),
            'Description': list(feature_desc.values())
        })
        st.dataframe(desc_df, use_container_width=True)
        
        st.subheader("Corr√©lations entre features")
        numeric_cols = user_features.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 1:
            corr_matrix = user_features[numeric_cols].corr().round(2)
            fig = px.imshow(corr_matrix, text_auto=True,
                          title="Matrice de corr√©lation")
            st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.markdown('<h2 class="sub-header">Features Transaction</h2>', unsafe_allow_html=True)
        
        st.metric("Nombre de transactions", tx_features.shape[0])
        st.metric("Nombre de features", tx_features.shape[1])
        
        st.subheader("Aper√ßu des features")
        st.dataframe(tx_features.head(10), use_container_width=True)
        
        st.subheader("Description des features")
        feature_desc = get_transaction_feature_description()
        desc_df = pd.DataFrame({
            'Feature': list(feature_desc.keys()),
            'Description': list(feature_desc.values())
        })
        st.dataframe(desc_df, use_container_width=True)

def page_acp(user_features):
    """Page d'analyse PCA avanc√©e."""
    st.markdown('<h1 class="main-header">üî¨ Analyse en Composantes Principales Avanc√©e</h1>', unsafe_allow_html=True)
    
    # ==================== SECTION 1: INTRODUCTION P√âDAGOGIQUE ====================
    st.markdown("""
    <div class="info-box">
    <h3>üéØ Objectif scientifique de l'ACP</h3>
    <p>L'Analyse en Composantes Principales est une <b>technique d'alg√®bre lin√©aire</b> qui permet de :</p>
    <ul>
    <li><b>R√©duire la dimensionnalit√©</b> tout en conservant l'information maximale</li>
    <li><b>Identifier les axes de variance</b> principaux dans les donn√©es</li>
    <li><b>Visualiser les corr√©lations</b> entre variables multidimensionnelles</li>
    <li><b>D√©tecter les patterns cach√©s</b> et structures latentes</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Badges scientifiques
    st.markdown("""
    <div style="display: flex; gap: 10px; margin: 20px 0;">
        <span class="badge" style="background-color: #2E7D32; color: white; padding: 8px 15px; border-radius: 20px; font-weight: bold;">üßÆ Alg√®bre Lin√©aire</span>
        <span class="badge" style="background-color: #1565C0; color: white; padding: 8px 15px; border-radius: 20px; font-weight: bold;">üìà Analyse Multivari√©e</span>
        <span class="badge" style="background-color: #6A1B9A; color: white; padding: 8px 15px; border-radius: 20px; font-weight: bold;">üîç R√©duction Dimensionnelle</span>
        <span class="badge" style="background-color: #C2185B; color: white; padding: 8px 15px; border-radius: 20px; font-weight: bold;">üìä Statistiques Avanc√©es</span>
    </div>
    """, unsafe_allow_html=True)
    
    # Colonnes d'explication
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
        <h4>üéØ Principe math√©matique</h4>
        <p><b>Diagonalisation</b> de la matrice de covariance</p>
        <p><b>Vecteurs propres</b> = directions de variance maximale</p>
        <p><b>Valeurs propres</b> = importance des axes</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
        <h4>üìê Objectifs analytiques</h4>
        <p><b>1. Simplification</b> : n ‚Üí k dimensions</p>
        <p><b>2. Interpr√©tation</b> : comprendre les relations</p>
        <p><b>3. Visualisation</b> : repr√©senter l'essentiel</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
        <h4>üîç Applications fintech</h4>
        <p><b>Segmentation clients</b> : profils comportementaux</p>
        <p><b>D√©tection patterns</b> : transactions atypiques</p>
        <p><b>Analyse risques</b> : corr√©lations cach√©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ==================== SECTION 2: PR√âPARATION DES DONN√âES ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">üîß Pr√©paration des Donn√©es</h2>', unsafe_allow_html=True)
    
    with st.expander("üìã Processus de pr√©traitement avanc√©", expanded=True):
        st.markdown("""
        ### Pipeline de pr√©paration rigoureux
        
        **√âtape 1 : V√©rification des types de donn√©es**
        - Identification variables num√©riques vs cat√©gorielles
        - Conversion optimale pour pr√©servation information
        
        **√âtape 2 : Traitement des valeurs manquantes**
        - Analyse pattern de manquants
        - Imputation par m√©diane/moyenne selon distribution
        - Suppression si >50% manquants
        
        **√âtape 3 : Gestion des outliers**
        - D√©tection par scores Z
        - Winsorization aux percentiles 1 et 99
        - Pr√©servation variance sans distortion
        
        **√âtape 4 : Standardisation**
        - Centrage (moyenne = 0)
        - R√©duction (√©cart-type = 1)
        - Comparabilit√© des variables
        """)
        
        # Afficher les statistiques de pr√©paration
        if not user_features.empty:
            st.subheader("üìä Statistiques descriptives avant PCA")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Nombre d'observations", f"{user_features.shape[0]:,}")
                st.metric("Variables initiales", user_features.shape[1])
                
                # Types de donn√©es
                dtype_counts = user_features.dtypes.value_counts()
                st.write("**Types de donn√©es :**")
                for dtype, count in dtype_counts.items():
                    st.write(f"- {dtype}: {count} variables")
            
            with col2:
                # Valeurs manquantes
                missing = user_features.isna().sum()
                missing_pct = (missing / len(user_features) * 100).round(2)
                
                st.write("**Valeurs manquantes :**")
                if missing.sum() > 0:
                    missing_df = pd.DataFrame({
                        'Variable': missing.index,
                        'Manquants': missing.values,
                        '%': missing_pct.values
                    })
                    missing_df = missing_df[missing_df['Manquants'] > 0]
                    st.dataframe(missing_df, use_container_width=True, hide_index=True)
                else:
                    st.success("‚úÖ Aucune valeur manquante")
    
    # ==================== SECTION 3: CONFIGURATION DE L'ANALYSE ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">‚öôÔ∏è Configuration de l\'Analyse PCA</h2>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Param√®tres avanc√©s
        st.subheader("Param√®tres analytiques")
        
        tab1, tab2, tab3 = st.tabs(["üìè Composantes", "üîç Qualit√©", "üéØ Avanc√©"])
        
        with tab1:
            max_components = min(10, user_features.shape[1])
            n_components = st.slider(
                "Nombre de composantes √† calculer",
                min_value=2,
                max_value=max_components,
                value=min(4, max_components),
                help="Nombre d'axes principaux √† extraire"
            )
            
            variance_threshold = st.slider(
                "Seuil de variance cumul√©e",
                min_value=0.5,
                max_value=0.99,
                value=0.9,
                step=0.01,
                help="Pourcentage minimum de variance √† expliquer"
            )
        
        with tab2:
            compute_advanced = st.checkbox(
                "Calculer m√©triques avanc√©es",
                value=True,
                help="KMO, Bartlett, communaut√©s, stabilit√© bootstrap"
            )
            
            perform_validation = st.checkbox(
                "Validation crois√©e",
                value=True,
                help="√âvaluation de la robustesse du mod√®le"
            )
        
        with tab3:
            random_state = st.number_input(
                "Seed al√©atoire",
                min_value=0,
                max_value=1000,
                value=42,
                help="Pour la reproductibilit√© des r√©sultats"
            )
            
            bootstrap_samples = st.slider(
                "√âchantillons bootstrap",
                min_value=10,
                max_value=500,
                value=100,
                help="Pour l'analyse de stabilit√©"
            )
    
    with col2:
        st.subheader("üéØ Crit√®res de d√©cision")
        
        st.markdown("""
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 10px; border-left: 4px solid #4CAF50;">
        <h4>üìä R√®gles de s√©lection</h4>
        
        **1. R√®gle de Kaiser**
        - Valeurs propres > 1
        - Composantes significatives
        
        **2. Scree plot (Cattell)**
        - Point d'inflexion
        - Diminution marginale
        
        **3. Variance cumul√©e**
        - Minimum 70-80%
        - Optimal 85-95%
        
        **4. Interpr√©tabilit√©**
        - Loading > |0.3|
        - Sens m√©tier clair
        </div>
        """, unsafe_allow_html=True)
    
    # ==================== SECTION 4: EX√âCUTION DE L'ANALYSE ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">üöÄ Ex√©cution de l\'Analyse PCA</h2>', unsafe_allow_html=True)
    
    if st.button("üî¨ Lancer l'analyse PCA avanc√©e", type="primary", use_container_width=True):
        with st.spinner("üßÆ Calcul en cours... Cette analyse peut prendre quelques secondes"):
            try:
                # Calcul PCA avec la fonction standard
                pca_result = compute_pca_cached(user_features, n_components)
                
                # ==================== SECTION 4.1: R√âSULTATS GLOBAUX ====================
                st.success("‚úÖ Analyse PCA termin√©e avec succ√®s !")
                
                # M√©triques de qualit√© globale
                st.subheader("üìà M√©triques de qualit√© globale")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        "Variance expliqu√©e totale",
                        f"{pca_result['cumulative_variance_ratio'][-1]:.1%}",
                        help="Proportion totale de variance conserv√©e"
                    )
                
                with col2:
                    st.metric(
                        "Nombre de composantes",
                        n_components,
                        help="Axes principaux calcul√©s"
                    )
                
                with col3:
                    st.metric(
                        "Variables originales",
                        user_features.shape[1],
                        help="R√©duction de dimension"
                    )
                
                # ==================== SECTION 4.2: SCREE PLOT ====================
                st.markdown("---")
                st.subheader("üìä Scree Plot - Analyse des valeurs propres")
                
                eigenvalues = pca_result['explained_variance']
                explained_variance_ratio = pca_result['explained_variance_ratio']
                cumulative_variance_ratio = pca_result['cumulative_variance_ratio']
                
                fig_scree = make_subplots(
                    rows=1, cols=2,
                    subplot_titles=("Variance expliqu√©e par composante", "Variance cumul√©e"),
                )
                
                # Plot 1: Variance par composante
                fig_scree.add_trace(
                    go.Bar(
                        x=[f'PC{i+1}' for i in range(len(explained_variance_ratio))],
                        y=explained_variance_ratio * 100,
                        name='% Variance',
                        marker_color='#1f77b4',
                        opacity=0.7
                    ),
                    row=1, col=1
                )
                
                # Plot 2: Variance cumul√©e
                fig_scree.add_trace(
                    go.Scatter(
                        x=[f'PC{i+1}' for i in range(len(cumulative_variance_ratio))],
                        y=cumulative_variance_ratio * 100,
                        name='Variance cumul√©e',
                        mode='lines+markers',
                        line=dict(color='#ff7f0e', width=3),
                        marker=dict(size=8)
                    ),
                    row=1, col=2
                )
                
                # Seuil de variance
                fig_scree.add_hline(
                    y=variance_threshold * 100,
                    line_dash="dash",
                    line_color="red",
                    annotation_text=f"Seuil {variance_threshold:.0%}",
                    annotation_position="right",
                    row=1, col=2
                )
                
                fig_scree.update_layout(
                    height=400,
                    showlegend=True,
                    title_text="Analyse dimensionnelle - Crit√®res de d√©cision"
                )
                
                fig_scree.update_yaxes(title_text="% Variance", row=1, col=1)
                fig_scree.update_yaxes(title_text="% Variance cumul√©e", row=1, col=2)
                
                st.plotly_chart(fig_scree, use_container_width=True)
                
                # ==================== SECTION 4.3: TABLEAU DES R√âSULTATS ====================
                st.subheader("üìã Tableau synth√©tique des r√©sultats")
                
                summary_data = {
                    'Composante': [f'PC{i+1}' for i in range(n_components)],
                    'Variance expliqu√©e': [f'{v:.1%}' for v in explained_variance_ratio],
                    'Variance cumul√©e': [f'{v:.1%}' for v in cumulative_variance_ratio],
                    'Valeur propre': [f'{v:.3f}' for v in eigenvalues]
                }
                
                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True, hide_index=True)
                
                # ==================== SECTION 4.4: CERCLE DES CORR√âLATIONS ====================
                if n_components >= 2:
                    st.markdown("---")
                    st.subheader("üéØ Cercle des Corr√©lations")
                    
                    # Options d'affichage
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        pc_x = st.selectbox(
                            "Axe horizontal (X)",
                            options=[f'PC{i+1}' for i in range(n_components)],
                            index=0
                        )
                    
                    with col2:
                        pc_y = st.selectbox(
                            "Axe vertical (Y)",
                            options=[f'PC{i+1}' for i in range(n_components)],
                            index=1 if n_components > 1 else 0
                        )
                    
                    # Extraction des indices
                    x_idx = int(pc_x[2:]) - 1
                    y_idx = int(pc_y[2:]) - 1
                    
                    # Cr√©ation du cercle des corr√©lations
                    loadings = pca_result['components']
                    feature_names = user_features.columns.tolist()
                    
                    x_loadings = loadings[x_idx]
                    y_loadings = loadings[y_idx]
                    
                    # Cr√©ation du graphique
                    fig_circle = go.Figure()
                    
                    # Cercle unit√©
                    theta = np.linspace(0, 2*np.pi, 100)
                    fig_circle.add_trace(go.Scatter(
                        x=np.cos(theta),
                        y=np.sin(theta),
                        mode='lines',
                        line=dict(color='gray', dash='dash'),
                        name='Cercle unit√©',
                        showlegend=False
                    ))
                    
                    # Axes
                    fig_circle.add_hline(y=0, line_color='gray', line_width=1)
                    fig_circle.add_vline(x=0, line_color='gray', line_width=1)
                    
                    # Variables
                    fig_circle.add_trace(go.Scatter(
                        x=x_loadings,
                        y=y_loadings,
                        mode='markers+text',
                        text=feature_names,
                        textposition="top center",
                        marker=dict(size=8, color='blue'),
                        name='Variables',
                        hovertemplate="<b>%{text}</b><br>X: %{x:.3f}<br>Y: %{y:.3f}<extra></extra>"
                    ))
                    
                    # Vecteurs
                    for i, feat in enumerate(feature_names):
                        fig_circle.add_trace(go.Scatter(
                            x=[0, x_loadings[i]],
                            y=[0, y_loadings[i]],
                            mode='lines',
                            line=dict(color='rgba(0,0,255,0.3)', width=1),
                            showlegend=False,
                            hoverinfo='skip'
                        ))
                    
                    fig_circle.update_layout(
                        title=f"Cercle des corr√©lations - {pc_x} vs {pc_y}",
                        xaxis_title=f"{pc_x} ({(explained_variance_ratio[x_idx]*100):.1f}%)",
                        yaxis_title=f"{pc_y} ({(explained_variance_ratio[y_idx]*100):.1f}%)",
                        height=600,
                        xaxis=dict(range=[-1.2, 1.2]),
                        yaxis=dict(range=[-1.2, 1.2]),
                        showlegend=False
                    )
                    
                    st.plotly_chart(fig_circle, use_container_width=True)
                
                # ==================== SECTION 4.5: CONCLUSIONS ====================
                st.markdown("---")
                st.markdown('<h2 class="sub-header">üéØ Conclusions et recommandations</h2>', unsafe_allow_html=True)
                
                with st.expander("üìã Synth√®se des r√©sultats", expanded=True):
                    st.markdown(f"""
                    ### üìä Synth√®se analytique
                    
                    **‚úÖ Points forts de l'analyse :**
                    1. **Variance bien captur√©e** : {cumulative_variance_ratio[-1]:.1%} avec {n_components} composantes
                    2. **Compression r√©ussie** : R√©duction de {user_features.shape[1]} √† {n_components} dimensions
                    3. **Interpr√©tabilit√©** : Les composantes principales sont faciles √† interpr√©ter
                    
                    **üéØ Principaux axes d'interpr√©tation :**
                    1. **PC1** ({explained_variance_ratio[0]:.1%}) : Premier axe de variance
                    2. **PC2** ({explained_variance_ratio[1]:.1%}) : Deuxi√®me axe orthogonal
                    
                    ### üìà Recommandations pratiques
                    
                    **Pour la segmentation clients :**
                    1. Utiliser PC1 et PC2 pour la visualisation 2D
                    2. Regrouper les utilisateurs proches dans l'espace r√©duit
                    3. Identifier les profils extr√™mes aux coins du nuage
                    
                    **Pour la r√©duction dimensionnelle :**
                    1. Conserver {min(n_components + 1, user_features.shape[1])} composantes pour >95% de variance
                    2. Supprimer les features avec faible variance
                    3. Valider avec une m√©thode de clustering (KMeans)
                    
                    **Prochaines √©tapes :**
                    - Appliquer KMeans sur les scores PCA
                    - Analyser les profils des clusters
                    - D√©tecter les anomalies transactionnelles
                    """)
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'analyse PCA: {str(e)}")
                with st.expander("üîß D√©tails techniques"):
                    st.write(f"**Erreur :** {e}")
                    st.write(f"**Shape des donn√©es :** {user_features.shape}")
                    st.write(f"**Colonnes :** {user_features.columns.tolist()}")

    else:
        # Mode attente
        st.info("üëÜ **Cliquez sur le bouton ci-dessus pour lancer l'analyse PCA**")

def page_kmeans(user_features):
    """Page de segmentation KMeans."""
    st.markdown('<h1 class="main-header">üë• Segmentation des Utilisateurs</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h3>üéØ Objectif du Clustering</h3>
    <p>KMeans permet de :</p>
    <ul>
    <li><b>Regrouper les utilisateurs</b> en clusters homog√®nes</li>
    <li><b>Identifier des segments</b> avec comportements similaires</li>
    <li><b>Personnaliser les offres</b> selon les profils d√©tect√©s</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Param√®tres
    st.sidebar.subheader("Param√®tres KMeans")
    k_min = st.sidebar.number_input("k minimum", min_value=2, max_value=10, value=2)
    k_max = st.sidebar.number_input("k maximum", min_value=k_min+1, max_value=15, value=8)
    
    # Choix du nombre de clusters
    st.markdown('<h2 class="sub-header">Choix du Nombre de Clusters</h2>', unsafe_allow_html=True)
    
    # Courbe du coude
    ks, inertias = compute_elbow_cached(user_features, k_min, k_max)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("M√©thode du Coude")
        df_elbow = pd.DataFrame({'k': ks, 'inertia': inertias})
        
        fig = px.line(df_elbow, x='k', y='inertia', markers=True,
                     title="Courbe du coude - Inertia vs k")
        fig.add_vline(x=suggest_optimal_k(user_features, k_min, k_max, 'elbow'),
                     line_dash="dash", line_color="red")
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
        **üí° Interpr√©tation :**
        - L'inertie mesure la compacit√© des clusters
        - On cherche le "coude" o√π la diminution ralentit
        - Point d'inflexion = bon compromis compacit√©/simplicit√©
        """)
    
    with col2:
        st.subheader("Score de Silhouette")
        ks_sil, silhouette_scores = compute_silhouette_cached(user_features, k_min, k_max)
        
        df_sil = pd.DataFrame({'k': ks_sil, 'silhouette': silhouette_scores})
        df_sil = df_sil.dropna()  # Enlever k=1
        
        fig = px.line(df_sil, x='k', y='silhouette', markers=True,
                     title="Score de silhouette vs k")
        
        if not df_sil.empty:
            best_k = df_sil.loc[df_sil['silhouette'].idxmax(), 'k']
            fig.add_vline(x=best_k, line_dash="dash", line_color="green")
        
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
        **üí° Interpr√©tation :**
        - Score entre -1 et 1
        - Proche de 1 = clusters bien s√©par√©s
        - Proche de 0 = recouvrement important
        - On cherche le k qui maximise ce score
        """)
    
    # Choix final de k
    st.subheader("Choix du Nombre de Clusters")
    
    suggested_k_elbow = suggest_optimal_k(user_features, k_min, k_max, 'elbow')
    suggested_k_sil = suggest_optimal_k(user_features, k_min, k_max, 'silhouette')
    suggested_k_combined = suggest_optimal_k(user_features, k_min, k_max, 'combined')
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Sugg√©r√© (coude)", suggested_k_elbow)
    with col2:
        st.metric("Sugg√©r√© (silhouette)", suggested_k_sil)
    with col3:
        st.metric("Sugg√©r√© (combin√©)", suggested_k_combined)
    
    chosen_k = st.slider(
        "Nombre de clusters k pour l'entra√Ænement",
        min_value=k_min,
        max_value=k_max,
        value=int(suggested_k_combined)
    )
    
    # Entra√Ænement KMeans
    clustering_result = train_kmeans_cached(user_features, chosen_k)
    
    # Visualisation des clusters
    st.markdown('<h2 class="sub-header">Visualisation des Clusters</h2>', unsafe_allow_html=True)
    
    X_transformed = clustering_result['X_transformed']
    labels = clustering_result['cluster_labels']
    
    df_clusters = pd.DataFrame({
        'PC1': X_transformed[:, 0],
        'PC2': X_transformed[:, 1],
        'Cluster': labels.astype(str),
        'user_id': user_features.index
    })
    
    fig = px.scatter(df_clusters, x='PC1', y='PC2', color='Cluster',
                    hover_data=['user_id'],
                    title=f"Clusters KMeans (k={chosen_k})",
                    color_discrete_sequence=px.colors.qualitative.Set3)
    st.plotly_chart(fig, use_container_width=True)
    
    # M√©triques de qualit√©
    st.subheader("Qualit√© du Clustering")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Score Silhouette", f"{clustering_result['silhouette_score']:.3f}")
    with col2:
        st.metric("Indice Davies-Bouldin", f"{clustering_result['davies_bouldin_score']:.3f}")
    with col3:
        st.metric("Inertie", f"{clustering_result['inertia']:.1f}")
    
    # Profils des clusters
    st.markdown('<h2 class="sub-header">Profils des Clusters</h2>', unsafe_allow_html=True)
    
    cluster_profiles = get_cluster_profiles(user_features, clustering_result)
    
    if not cluster_profiles.empty:
        # Afficher les statistiques principales
        display_cols = [col for col in cluster_profiles.columns 
                       if any(x in col for x in ['mean', 'size', 'pct'])]
        
        st.dataframe(
            cluster_profiles[display_cols].style.format("{:.2f}"),
            use_container_width=True
        )
        
        # Visualisation comparative
        st.subheader("Comparaison des Clusters")
        
        # S√©lection des features √† comparer
        numeric_cols = user_features.select_dtypes(include=[np.number]).columns
        selected_features = st.multiselect(
            "Features √† comparer",
            options=numeric_cols.tolist(),
            default=numeric_cols[:3].tolist() if len(numeric_cols) >= 3 else numeric_cols.tolist()
        )
        
        if selected_features:
            # Pr√©parer les donn√©es pour la visualisation
            user_features_with_clusters = user_features.copy()
            user_features_with_clusters['Cluster'] = clustering_result['cluster_labels'].astype(str)
            
            # Boxplots par cluster
            for feature in selected_features:
                if feature in user_features.columns:
                    fig = px.box(user_features_with_clusters, 
                                x='Cluster', y=feature,
                                title=f"Distribution de {feature} par cluster")
                    st.plotly_chart(fig, use_container_width=True)
    
    # Exploration d'un cluster sp√©cifique
    st.markdown('<h2 class="sub-header">Exploration d\'un Cluster</h2>', unsafe_allow_html=True)
    
    selected_cluster = st.selectbox(
        "Choisir un cluster √† explorer",
        options=sorted(np.unique(labels))
    )
    
    cluster_indices = np.where(labels == selected_cluster)[0]
    cluster_users = user_features.iloc[cluster_indices]
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.metric(f"Utilisateurs dans cluster {selected_cluster}", len(cluster_users))
        
        # Statistiques du cluster
        if not cluster_users.empty:
            stats = cluster_users.describe().round(2)
            st.dataframe(stats, use_container_width=True)
    
    with col2:
        if not cluster_users.empty:
            # Visualisation radar des caract√©ristiques moyennes
            mean_values = cluster_users.mean(numeric_only=True)
            top_features = mean_values.nlargest(8)
            
            fig = px.bar(x=top_features.index, y=top_features.values,
                        title=f"Top 8 caract√©ristiques - Cluster {selected_cluster}")
            st.plotly_chart(fig, use_container_width=True)


def page_anomalies(df_raw, tx_features):
    """Page de d√©tection d'anomalies."""
    st.markdown('<h1 class="main-header">üö® D√©tection d\'Anomalies Transactionnelles</h1>', unsafe_allow_html=True)
    
    # ==================== SECTION 1: INTRODUCTION P√âDAGOGIQUE ====================
    st.markdown("""
    <div class="info-box">
    <h3>üéØ Objectif de cette analyse</h3>
    <p>Identifier des transactions <b>atypiques</b> pouvant correspondre √† :</p>
    <ul>
    <li>Fraude ou abus de cashback</li>
    <li>Comportements suspects d'utilisateurs</li>
    <li>Erreurs de saisie ou bugs syst√®me</li>
    <li>Patterns transactionnels rares</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Explication du concept avec des colonnes
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
        <h4>üìä Isolation Forest</h4>
        <p><b>Principe :</b> For√™t d'arbres al√©atoires qui isolent les points</p>
        <p><b>Avantage :</b> Pas besoin de donn√©es labellis√©es</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
        <h4>üîç Contamination</h4>
        <p><b>D√©finition :</b> Proportion attendue d'anomalies</p>
        <p><b>Typique :</b> 1-5% selon le domaine</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
        <h4>üìà Score d'anomalie</h4>
        <p><b>Interpr√©tation :</b> Plus √©lev√© = plus anormal</p>
        <p><b>Seuil :</b> G√©n√©ralement > percentile 95</p>
        </div>
        """, unsafe_allow_html=True)
    
    # ==================== SECTION 2: PR√âPARATION DES DONN√âES ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">üìã Pr√©paration des Donn√©es</h2>', unsafe_allow_html=True)
    
    with st.expander("üîç Voir les features transactionnelles utilis√©es", expanded=True):
        # Afficher un r√©sum√© des features
        if not tx_features.empty:
            st.write(f"**Nombre de transactions analys√©es :** {len(tx_features):,}")
            st.write(f"**Nombre de features :** {tx_features.shape[1]}")
            
            # Statistiques descriptives
            st.subheader("Statistiques descriptives des features")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Types de donn√©es :**")
                dtype_counts = tx_features.dtypes.value_counts()
                for dtype, count in dtype_counts.items():
                    st.write(f"- {dtype}: {count} colonnes")
            
            with col2:
                st.write("**Valeurs manquantes :**")
                missing = tx_features.isna().sum()
                missing_pct = (missing / len(tx_features) * 100).round(2)
                missing_df = pd.DataFrame({
                    'Colonne': missing.index,
                    'Valeurs manquantes': missing.values,
                    'Pourcentage': missing_pct.values
                })
                st.dataframe(missing_df[missing_df['Valeurs manquantes'] > 0], 
                           use_container_width=True, hide_index=True)
            
            # Matrice de corr√©lation
            if tx_features.shape[1] > 1:
                st.subheader("üîó Matrice de corr√©lations")
                numeric_cols = tx_features.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 1:
                    corr_matrix = tx_features[numeric_cols].corr()
                    fig = px.imshow(corr_matrix, 
                                  title="Corr√©lations entre features transactionnelles",
                                  color_continuous_scale='RdBu',
                                  zmin=-1, zmax=1)
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.markdown("""
                    **üí° Interpr√©tation :**
                    - **Couleurs bleues** : Corr√©lation positive (variables √©voluent ensemble)
                    - **Couleurs rouges** : Corr√©lation n√©gative (variables √©voluent en opposition)
                    - **Variables fortement corr√©l√©es** peuvent √™tre redondantes
                    """)
    
    # ==================== SECTION 3: PARAM√âTRAGE DU MOD√àLE ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">‚öôÔ∏è Configuration du Mod√®le</h2>', unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        contamination = st.slider(
            "**Contamination** (proportion d'anomalies attendue)",
            min_value=0.001,
            max_value=0.2,
            value=0.02,
            step=0.001,
            help="""Param√®tre crucial qui influence la sensibilit√© du d√©tecteur.
            \n‚Ä¢ **Valeur faible (0.01)** : D√©tection tr√®s conservative
            \n‚Ä¢ **Valeur √©lev√©e (0.1)** : D√©tection plus agressive"""
        )
    
    with col2:
        n_estimators = st.slider(
            "**Nombre d'arbres**",
            min_value=10,
            max_value=500,
            value=100,
            step=10,
            help="Plus d'arbres = mod√®le plus stable mais plus lent"
        )
    
    with col3:
        # Bouton pour suggestion automatique
        if st.button("üéØ Sugg√©rer automatiquement", key="suggest_contamination"):
            try:
                suggested = suggest_contamination(tx_features)
                st.success(f"Contamination sugg√©r√©e: **{suggested:.3f}**")
                contamination = suggested
            except:
                st.info("Utilisez la valeur par d√©faut de 2%")
    
    # Explication technique
    st.markdown("""
    <div class="warning-box">
    <h4>üß† Fonctionnement d'Isolation Forest</h4>
    <p><b>Algorithme :</b></p>
    <ol>
    <li>Construction d'arbres de d√©cision al√©atoires</li>
    <li>Les anomalies sont <b>isol√©es plus rapidement</b> (moins de d√©cisions)</li>
    <li>Le score d'anomalie = longueur moyenne du chemin d'isolation</li>
    <li>Seuil automatique bas√© sur la contamination sp√©cifi√©e</li>
    </ol>
    <p><b>Avantages :</b> Pas besoin de labels, efficace sur donn√©es multidimensionnelles</p>
    </div>
    """, unsafe_allow_html=True)
    
    # ==================== SECTION 4: ENTRA√éNEMENT ET R√âSULTATS ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">üî¨ R√©sultats de la D√©tection</h2>', unsafe_allow_html=True)
    
    if st.button("üöÄ Lancer la d√©tection d'anomalies", type="primary", use_container_width=True):
        with st.spinner("üß† Entra√Ænement du mod√®le en cours..."):
            try:
                # 1. Entra√Ænement du mod√®le
                anomaly_result = train_isolation_forest(
                    tx_features, 
                    contamination=contamination,
                    n_estimators=n_estimators
                )
                
                # 2. Statistiques
                stats = get_anomaly_statistics(anomaly_result)
                
                # ==================== SECTION 4.1: M√âTRIQUES DE PERFORMANCE ====================
                st.success("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")
                
                # KPI Cards
                st.subheader("üìä M√©triques de performance")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        "Transactions analys√©es",
                        f"{stats['n_total']:,}",
                        help="Nombre total de transactions trait√©es"
                    )
                
                with col2:
                    st.metric(
                        "Anomalies d√©tect√©es",
                        f"{stats['n_anomalies']:,}",
                        delta=f"{stats['pct_anomalies']:.1f}%",
                        delta_color="inverse",
                        help="Nombre et pourcentage de transactions anormales"
                    )
                
                with col3:
                    st.metric(
                        "Score moyen",
                        f"{stats['score_mean']:.3f}",
                        help="Score d'anomalie moyen (0 = normal, >0 = anormal)"
                    )
                
                with col4:
                    st.metric(
                        "Seuil Q95",
                        f"{stats['score_q95']:.3f}",
                        help="95√®me percentile - seuil d'alerte recommand√©"
                    )
                
                # ==================== SECTION 4.2: DISTRIBUTION DES SCORES ====================
                st.subheader("üìà Distribution des scores d'anomalie")
                
                scores = anomaly_result['anomaly_scores']
                is_anomaly = anomaly_result['is_anomaly']
                
                # Cr√©er un DataFrame pour la visualisation
                df_scores = pd.DataFrame({
                    'Score': scores,
                    'Anomalie': is_anomaly,
                    'Cat√©gorie': np.where(is_anomaly, 'Anomalie', 'Normal')
                })
                
                # Graphique 1: Histogramme avec densit√©
                fig1 = px.histogram(
                    df_scores, 
                    x='Score',
                    color='Cat√©gorie',
                    nbins=50,
                    title="Distribution des scores d'anomalie",
                    color_discrete_map={'Normal': 'blue', 'Anomalie': 'red'},
                    opacity=0.7,
                    barmode='overlay'
                )
                
                # Ajouter une ligne verticale pour le seuil
                threshold = np.percentile(scores, 95)
                fig1.add_vline(
                    x=threshold, 
                    line_dash="dash", 
                    line_color="green",
                    annotation_text=f"Seuil 95% ({threshold:.3f})",
                    annotation_position="top right"
                )
                
                st.plotly_chart(fig1, use_container_width=True)
                
                # Graphique 2: Box plot par cat√©gorie
                fig2 = px.box(
                    df_scores,
                    x='Cat√©gorie',
                    y='Score',
                    color='Cat√©gorie',
                    title="Distribution comparative des scores",
                    points="all"
                )
                st.plotly_chart(fig2, use_container_width=True)
                
                # ==================== SECTION 4.3: ANALYSE DES ANOMALIES ====================
                st.subheader("üîç Analyse d√©taill√©e des anomalies")
                
                # Seuil interactif
                score_threshold = st.slider(
                    "**Seuil de score pour filtrer les anomalies**",
                    min_value=float(scores.min()),
                    max_value=float(scores.max()),
                    value=float(threshold),
                    step=0.01,
                    help="Ajustez ce seuil pour affiner la d√©tection"
                )
                
                # Analyser les anomalies
                df_anomalies = analyze_anomalies(df_raw, anomaly_result, score_threshold)
                high_score_tx = df_anomalies[df_anomalies['is_above_threshold']].copy()
                
                st.metric(
                    f"Transactions au-dessus du seuil ({score_threshold:.3f})",
                    f"{len(high_score_tx):,}",
                    delta=f"{(len(high_score_tx)/len(df_raw)*100):.1f}%",
                    delta_color="inverse"
                )
                
                if not high_score_tx.empty:
                    # Afficher les transactions suspectes
                    st.subheader(f"üìã Top {min(20, len(high_score_tx))} transactions les plus suspectes")
                    
                    # Colonnes √† afficher
                    display_cols = [
                        'transaction_id', 'user_id', 'transaction_date',
                        'product_category', 'product_amount', 'cashback',
                        'payment_method', 'anomaly_score'
                    ]
                    
                    # Garder seulement les colonnes pr√©sentes
                    available_cols = [col for col in display_cols if col in high_score_tx.columns]
                    
                    # Formater le DataFrame
                    display_df = high_score_tx[available_cols + ['anomaly_score']].head(20).copy()
                    
                    # Ajouter un indicateur visuel
                    def color_anomaly_score(val):
                        if val > threshold * 1.5:
                            return 'background-color: #ffcccc'  # Rouge clair
                        elif val > threshold:
                            return 'background-color: #fff3cd'  # Jaune clair
                        else:
                            return ''
                    
                    styled_df = display_df.style.format({
                        'anomaly_score': '{:.3f}',
                        'product_amount': '{:.2f}',
                        'cashback': '{:.2f}'
                    }).applymap(color_anomaly_score, subset=['anomaly_score'])
                    
                    st.dataframe(styled_df, use_container_width=True)
                    
                    # ==================== SECTION 4.4: ANALYSE DES PATTERNS ====================
                    st.subheader("üìä Patterns des anomalies d√©tect√©es")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # Cat√©gories des anomalies
                        if 'product_category' in high_score_tx.columns:
                            cat_counts = high_score_tx['product_category'].value_counts().head(10)
                            fig_cat = px.bar(
                                x=cat_counts.index, 
                                y=cat_counts.values,
                                title="Cat√©gories de produits des anomalies",
                                labels={'x': 'Cat√©gorie', 'y': 'Nombre'},
                                color=cat_counts.values,
                                color_continuous_scale='reds'
                            )
                            st.plotly_chart(fig_cat, use_container_width=True)
                    
                    with col2:
                        # M√©thodes de paiement
                        if 'payment_method' in high_score_tx.columns:
                            pm_counts = high_score_tx['payment_method'].value_counts().head(10)
                            fig_pm = px.pie(
                                values=pm_counts.values,
                                names=pm_counts.index,
                                title="R√©partition par m√©thode de paiement",
                                hole=0.4
                            )
                            st.plotly_chart(fig_pm, use_container_width=True)
                    
                    # Distribution des montants
                    if 'product_amount' in high_score_tx.columns:
                        st.subheader("üí∞ Analyse des montants")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            fig_amount = px.box(
                                high_score_tx,
                                y='product_amount',
                                title="Distribution des montants des anomalies",
                                points="all"
                            )
                            st.plotly_chart(fig_amount, use_container_width=True)
                        
                        with col2:
                            # Comparaison avec l'ensemble des donn√©es
                            if 'product_amount' in df_raw.columns:
                                fig_compare = go.Figure()
                                fig_compare.add_trace(go.Box(
                                    y=df_raw['product_amount'],
                                    name='Toutes transactions',
                                    boxpoints=False
                                ))
                                fig_compare.add_trace(go.Box(
                                    y=high_score_tx['product_amount'],
                                    name='Anomalies',
                                    boxpoints=False,
                                    marker_color='red'
                                ))
                                fig_compare.update_layout(
                                    title="Comparaison des montants",
                                    yaxis_title="Montant (‚Ç¨)",
                                    showlegend=True
                                )
                                st.plotly_chart(fig_compare, use_container_width=True)
                    
                    # ==================== SECTION 4.5: RAPPORT D'ANALYSE ====================
                    st.markdown("---")
                    st.markdown('<h2 class="sub-header">üìÑ Rapport d\'Analyse</h2>', unsafe_allow_html=True)
                    
                    with st.expander("üìã Synth√®se des r√©sultats", expanded=True):
                        st.markdown(f"""
                        ### R√©sum√© ex√©cutif
                        
                        **üìä Donn√©es analys√©es :**
                        - {stats['n_total']:,} transactions trait√©es
                        - {tx_features.shape[1]} features utilis√©es
                        - Contamination param√©tr√©e : {contamination:.1%}
                        
                        **üö® R√©sultats de d√©tection :**
                        - **{stats['n_anomalies']:,} anomalies** d√©tect√©es ({stats['pct_anomalies']:.1f}% du total)
                        - Score moyen : {stats['score_mean']:.3f}
                        - Seuil de d√©tection (Q95) : {stats['score_q95']:.3f}
                        
                        **üéØ Transactions les plus suspectes :**
                        - Score maximum : {stats['score_max']:.3f}
                        - {len(high_score_tx):,} transactions au-dessus du seuil ({score_threshold:.3f})
                        
                        **üí° Recommandations :**
                        1. **V√©rifier manuellement** les transactions avec score > {threshold:.3f}
                        2. **Analyser les patterns** r√©currents dans les cat√©gories/anomalies
                        3. **Ajuster la contamination** selon les r√©sultats m√©tier
                        """)
                    
                    # ==================== SECTION 4.6: EXPORT DES R√âSULTATS ====================
                    st.subheader("üíæ Export des r√©sultats")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # CSV des anomalies
                        csv = high_score_tx.to_csv(index=False)
                        st.download_button(
                            label="üì• T√©l√©charger les anomalies (CSV)",
                            data=csv,
                            file_name="anomalies_detectees.csv",
                            mime="text/csv",
                            help="Exporte la liste des transactions anormales"
                        )
                    
                    with col2:
                        # Rapport PDF (simul√©)
                        if st.button("üìÑ G√©n√©rer un rapport PDF", help="G√©n√®re un rapport d√©taill√©"):
                            st.info("""
                            **Fonctionnalit√© PDF :**
                            Pour un d√©ploiement complet, cette fonctionnalit√© pourrait :
                            1. G√©n√©rer un PDF avec tous les graphiques
                            2. Inclure les statistiques d√©taill√©es
                            3. Ajouter des recommandations m√©tier
                            4. Exporter au format professionnel
                            """)
                
                else:
                    st.warning("‚ö†Ô∏è Aucune transaction ne d√©passe le seuil actuel.")
                    st.info("""
                    **Suggestions :**
                    1. R√©duisez le seuil de d√©tection
                    2. Augmentez la contamination
                    3. V√©rifiez la qualit√© des donn√©es
                    """)
                
                # ==================== SECTION 5: √âVALUATION DU MOD√àLE ====================
                st.markdown("---")
                st.markdown('<h2 class="sub-header">üéØ √âvaluation du Mod√®le</h2>', unsafe_allow_html=True)
                
                with st.expander("üß™ Tests et validations", expanded=True):
                    st.markdown("""
                    ### M√©thodologie d'√©valuation
                    
                    **üìè M√©triques utilis√©es :**
                    
                    1. **Distribution des scores** : V√©rification de la s√©paration normale/anomalie
                    2. **Consistance des r√©sultats** : R√©partition coh√©rente avec la contamination
                    3. **Analyse des features** : Importance des variables dans la d√©cision
                    
                    **‚úÖ Crit√®res de qualit√© :**
                    - **S√©paration claire** entre scores normaux et anormaux
                    - **Distribution logique** des anomalies d√©tect√©es
                    - **Robustesse** aux variations de param√®tres
                    - **Interpr√©tabilit√©** des r√©sultats
                    
                    **üî¨ Prochaines √©tapes possibles :**
                    - Validation crois√©e sur diff√©rentes p√©riodes
                    - Comparaison avec d'autres algorithmes (LOF, One-Class SVM)
                    - Int√©gration de features temporelles suppl√©mentaires
                    """)
                    
                    # Visualisation de la qualit√©
                    if not df_scores.empty:
                        # QQ-plot pour v√©rifier la distribution
                        from scipy import stats
                        
                        fig_qq = go.Figure()
                        
                        # Donn√©es pour QQ-plot
                        normal_scores = df_scores[df_scores['Cat√©gorie'] == 'Normal']['Score']
                        theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, len(normal_scores)))
                        
                        fig_qq.add_trace(go.Scatter(
                            x=theoretical_quantiles,
                            y=np.sort(normal_scores),
                            mode='markers',
                            name='QQ-plot',
                            marker=dict(size=8, opacity=0.6)
                        ))
                        
                        # Ligne de r√©f√©rence
                        min_val = min(theoretical_quantiles.min(), normal_scores.min())
                        max_val = max(theoretical_quantiles.max(), normal_scores.max())
                        fig_qq.add_trace(go.Scatter(
                            x=[min_val, max_val],
                            y=[min_val, max_val],
                            mode='lines',
                            name='y=x',
                            line=dict(dash='dash', color='red')
                        ))
                        
                        fig_qq.update_layout(
                            title="QQ-plot : Normalit√© des scores 'normaux'",
                            xaxis_title="Quantiles th√©oriques (Normale)",
                            yaxis_title="Quantiles observ√©s",
                            showlegend=True
                        )
                        
                        st.plotly_chart(fig_qq, use_container_width=True)
                        
                        st.markdown("""
                        **üí° Interpr√©tation du QQ-plot :**
                        - **Points sur la ligne rouge** : Distribution normale
                        - **Points au-dessus de la ligne** : Queue de distribution plus √©paisse
                        - **Points en-dessous** : Distribution diff√©rente de la normale
                        """)
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la d√©tection d'anomalies: {str(e)}")
                
                # Aide au d√©bogage
                with st.expander("üîß Aide au d√©bogage"):
                    st.markdown(f"""
                    **Erreur d√©taill√©e :** `{e}`
                    
                    **Solutions possibles :**
                    
                    1. **V√©rifiez les donn√©es :**
                       - Les features doivent √™tre num√©riques
                       - Pas de valeurs manquantes excessives
                       - Pas de colonnes avec variance nulle
                    
                    2. **Param√®tres :**
                       - R√©duisez la contamination
                       - Diminuez le nombre d'arbres
                       - Utilisez moins de features
                    
                    3. **Donn√©es d'exemple :**
                       - T√©l√©chargez notre [fichier d'exemple](https://example.com/sample_data.csv)
                       - Testez avec 100-200 transactions d'abord
                    """)
                    
                    # Affichage des donn√©es pour d√©bogage
                    if not tx_features.empty:
                        st.write("**Aper√ßu des donn√©es :**")
                        st.dataframe(tx_features.head(), use_container_width=True)
                        
                        st.write("**Statistiques :**")
                        st.write(f"- Shape: {tx_features.shape}")
                        st.write(f"- Types: {tx_features.dtypes.unique()}")
                        st.write(f"- NaN: {tx_features.isna().sum().sum()}")
    else:
        # Mode attente
        st.info("üëÜ **Cliquez sur le bouton ci-dessus pour lancer la d√©tection d'anomalies**")
        
        # Exemple de ce qui va se passer
        with st.expander("üéØ Pr√©visualisation de l'analyse"):
            st.markdown("""
            ### Ce que vous allez obtenir :
            
            1. **üìä M√©triques de performance** :
               - Nombre d'anomalies d√©tect√©es
               - Pourcentage d'anomalies
               - Scores statistiques
            
            2. **üìà Visualisations** :
               - Distribution des scores
               - Comparaison normale/anomalie
               - Analyse par cat√©gorie
            
            3. **üîç Analyse d√©taill√©e** :
               - Liste des transactions suspectes
               - Patterns r√©currents
               - Recommandations
            
            4. **üíæ Export** :
               - Fichier CSV des anomalies
               - Rapports synth√©tiques
            """)
            
            # Exemple visuel
            st.image("https://miro.medium.com/v2/resize:fit:1400/1*YRim7T6BqrSylr8EaqKqZQ.png", 
                    caption="Exemple de d√©tection d'anomalies avec Isolation Forest")
    
    # ==================== SECTION 6: POUR ALLER PLUS LOIN ====================
    st.markdown("---")
    st.markdown('<h2 class="sub-header">üöÄ Pour aller plus loin</h2>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["üìö Th√©orie", "üîß Techniques avanc√©es", "üìà Applications m√©tier"])
    
    with tab1:
        st.markdown("""
        ### Fondements th√©oriques
        
        **üìñ Isolation Forest (Liu et al., 2008)**
        
        **Principe :** Les anomalies sont rares et diff√©rentes ‚Üí elles sont isolables en peu de d√©cisions
        
        **Algorithme :**
        1. S√©lection al√©atoire d'une feature
        2. S√©lection al√©atoire d'une valeur de coupure
        3. R√©p√©tition jusqu'√† isolation compl√®te
        4. Score = longueur moyenne du chemin
        
        **Formule du score :**
        ```
        s(x, n) = 2^{-E(h(x))/c(n)}
        o√π :
        - h(x) = hauteur du chemin d'isolation
        - c(n) = hauteur moyenne d'un arbre binaire
        - E(h(x)) = esp√©rance sur plusieurs arbres
        ```
        
        **Avantages :**
        - Lin√©aire en temps et m√©moire
        - Efficace en haute dimension
        - Pas besoin de distance m√©trique
        """)
    
    with tab2:
        st.markdown("""
        ### Techniques avanc√©es
        
        **üéØ Am√©liorations possibles :**
        
        1. **Ensemble methods** :
           - Combinaison avec Local Outlier Factor (LOF)
           - Stacking de diff√©rents d√©tecteurs
           - Vote majoritaire
        
        2. **Features engineering** :
           - Features temporelles (tendance, saisonnalit√©)
           - Features de r√©seau (relations entre utilisateurs)
           - Encodages avanc√©s des cat√©gories
        
        3. **Validation** :
           - Validation temporelle (train/test sur p√©riodes diff√©rentes)
           - Simulation d'anomalies pour √©valuation
           - M√©triques m√©tier sp√©cifiques
        
        4. **Monitoring** :
           - D√©tection de concept drift
           - Mise √† jour incr√©mentale du mod√®le
           - Alertes en temps r√©el
        """)
    
    with tab3:
        st.markdown("""
        ### Applications m√©tier dans la fintech
        
        **üí∞ Cas d'usage :**
        
        1. **D√©tection de fraude** :
           - Transactions anormalement √©lev√©es
           - Patterns de cashback suspects
           - Multi-comptes abusifs
        
        2. **Surveillance r√©glementaire** :
           - Conformit√© AML (Anti-Money Laundering)
           - D√©tection de blanchiment
           - Transactions Politically Exposed Persons (PEP)
        
        3. **Exp√©rience client** :
           - D√©tection de bugs d'application
           - Transactions erron√©es
           - Probl√®mes de conversion devise
        
        4. **Business intelligence** :
           - Identification de segments sp√©ciaux
           - Opportunit√©s marketing
           - Optimisation des commissions
        
        **üìä ROI potentiel :**
        - R√©duction des pertes par fraude : **5-15%**
        - Am√©lioration de l'exp√©rience client : **+20% NPS**
        - Conformit√© r√©glementaire : **√âvite amendes**
        """)
        
def page_xai(df_raw, tx_features):
    """Page d'explications SHAP."""
    st.markdown('<h1 class="main-header">ü§ñ Explications par SHAP</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h3>üéØ Objectif de SHAP (SHapley Additive exPlanations)</h3>
    <p>SHAP permet de :</p>
    <ul>
    <li><b>Comprendre pourquoi</b> une transaction est jug√©e anormale</li>
    <li><b>Identifier les features</b> qui contribuent le plus √† la d√©cision</li>
    <li><b>Expliquer en termes simples</b> les pr√©dictions du mod√®le</li>
    </ul>
    </div>
    
    <div class="warning-box">
    <h4>üìä Interpr√©tation des valeurs SHAP</h4>
    <p><b>Valeur SHAP positive</b> = la feature augmente le score d'anomalie (rend la transaction plus suspecte)</p>
    <p><b>Valeur SHAP n√©gative</b> = la feature diminue le score d'anomalie (rend la transaction plus normale)</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Param√®tres
    st.sidebar.subheader("Param√®tres SHAP")
    
    contamination = st.sidebar.slider(
        "Contamination pour Isolation Forest",
        min_value=0.001,
        max_value=0.1,
        value=0.02,
        step=0.001,
        key="xai_contamination"
    )
    
    sample_size = st.sidebar.slider(
        "Taille de l'√©chantillon pour SHAP",
        min_value=50,
        max_value=500,
        value=200,
        step=50,
        help="Plus d'√©chantillons = plus pr√©cis mais plus lent"
    )
    
    # Entra√Ænement du mod√®le et calcul SHAP
    with st.spinner("Entra√Ænement du mod√®le et calcul SHAP..."):
        anomaly_result = train_isolation_forest(tx_features, contamination=contamination)
        shap_result = compute_shap_cached(
            anomaly_result['iforest'],
            anomaly_result['scaler'],
            tx_features,
            sample_size
        )
    
    # M√©triques globales
    shap_summary = generate_shap_summary(shap_result)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Transactions analys√©es", shap_summary['n_transactions'])
    with col2:
        st.metric("Features", shap_summary['n_features'])
    with col3:
        st.metric("Valeur SHAP moyenne", f"{shap_summary['shap_mean']:.4f}")
    
    # Importance globale des features
    st.markdown('<h2 class="sub-header">Importance Globale des Features</h2>', unsafe_allow_html=True)
    
    global_importance = pd.DataFrame(shap_summary['global_importance'])
    
    fig = px.bar(global_importance, x='mean_abs_shap', y='feature',
                orientation='h',
                title="Importance moyenne des features (valeur absolue SHAP)")
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("""
    **üí° Interpr√©tation :**
    - Les features en haut sont les plus importantes globalement
    - Elles influencent le plus les d√©cisions d'anomalie
    - Utile pour comprendre quelles variables surveiller
    """)
    
    # S√©lection d'une transaction
    st.markdown('<h2 class="sub-header">Analyse d\'une Transaction Sp√©cifique</h2>', unsafe_allow_html=True)
    
    # Pr√©parer les donn√©es pour la s√©lection
    df_sample_meta = df_raw.iloc[shap_result['indices']].copy()
    df_sample_meta['anomaly_score'] = anomaly_result['anomaly_scores'][shap_result['indices']]
    df_sample_meta['is_anomaly'] = anomaly_result['is_anomaly'][shap_result['indices']]
    df_sample_meta['sample_index'] = range(len(df_sample_meta))
    
    # Trier par score d'anomalie
    df_sample_meta = df_sample_meta.sort_values('anomaly_score', ascending=False)
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.subheader("Transactions √©chantillonn√©es (tri√©es par score)")
        
        display_cols = [
            'sample_index', 'transaction_id', 'user_id', 
            'product_amount', 'cashback', 'anomaly_score', 'is_anomaly'
        ]
        
        available_cols = [col for col in display_cols if col in df_sample_meta.columns]
        
        st.dataframe(
            df_sample_meta[available_cols]
            .head(20)
            .style.format({'anomaly_score': '{:.3f}'}),
            use_container_width=True
        )
    
    with col2:
        st.subheader("S√©lection")
        
        selected_idx = st.number_input(
            "Index dans l'√©chantillon",
            min_value=0,
            max_value=len(df_sample_meta) - 1,
            value=0,
            step=1
        )
    
    # Informations sur la transaction s√©lectionn√©e
    selected_tx = df_sample_meta.iloc[selected_idx]
    
    st.subheader(f"Transaction s√©lectionn√©e (Index: {selected_idx})")
    
    # Afficher les d√©tails
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Score d'anomalie", f"{selected_tx['anomaly_score']:.3f}")
    with col2:
        st.metric("Est anomalie", "‚úÖ Oui" if selected_tx['is_anomaly'] else "‚ùå Non")
    with col3:
        if 'transaction_id' in selected_tx:
            st.metric("ID Transaction", selected_tx['transaction_id'])
    
    # D√©tails complets
    with st.expander("üìã D√©tails complets de la transaction"):
        st.write(selected_tx)
    
    # Explications SHAP pour cette transaction
    st.markdown('<h2 class="sub-header">Explications SHAP D√©taill√©es</h2>', unsafe_allow_html=True)
    
    # R√©cup√©rer les contributions SHAP
    top_n = st.slider(
        "Nombre de features √† afficher",
        min_value=5,
        max_value=20,
        value=10
    )
    
    shap_contributions = get_top_shap_features(shap_result, selected_idx, top_n)
    
    # Bar plot des contributions
    fig = px.bar(shap_contributions.sort_values('shap_value'),
                x='shap_value', y='feature', orientation='h',
                color='shap_value',
                color_continuous_scale='RdBu',
                title=f"Contributions SHAP - Transaction {selected_idx}")
    
    fig.add_vline(x=0, line_width=2, line_dash="dash", line_color="black")
    st.plotly_chart(fig, use_container_width=True)
    
    # Table d√©taill√©e
    st.subheader("Table des contributions")
    st.dataframe(
        shap_contribinations.style.format({
            'shap_value': '{:.4f}',
            'abs_shap': '{:.4f}'
        }),
        use_container_width=True
    )
    
    # Explication en fran√ßais
    st.markdown('<h2 class="sub-header">Explication en Fran√ßais</h2>', unsafe_allow_html=True)
    
    explanation = explain_anomaly_in_french(
        shap_result, selected_idx, df_raw, top_n=5
    )
    
    st.markdown(f"""
    <div style="background-color: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid #4e73df;">
    {explanation}
    </div>
    """, unsafe_allow_html=True)
    
    # Waterfall plot (optionnel)
    if st.checkbox("Afficher le diagramme waterfall (d√©taill√©)"):
        st.subheader("Diagramme Waterfall SHAP")
        
        import shap
        
        # Cr√©er le plot waterfall
        shap_values_row = shap_result['shap_values'][selected_idx]
        expected_value = shap_result['explainer'].expected_value
        
        # Pour Isolation Forest, expected_value peut √™tre une liste
        if isinstance(expected_value, list):
            expected_value = expected_value[0]
        
        fig = shap.waterfall_plot(
            shap.Explanation(
                values=shap_values_row,
                base_values=expected_value,
                data=shap_result['X_sample'].iloc[selected_idx].values,
                feature_names=shap_result['feature_names']
            ),
            max_display=top_n,
            show=False
        )
        
        st.pyplot(fig)


# --------- Navigation principale --------- #

def main():
    """Fonction principale de l'application."""
    # Sidebar
    with st.sidebar:
        st.title("‚öôÔ∏è Configuration")
        
        st.markdown("---")
        st.subheader("üìÅ Donn√©es")
        
        uploaded_file = st.file_uploader(
            "Importer un fichier CSV",
            type=["csv"],
            help="Le fichier doit contenir les colonnes de transactions (user_id, product_amount, cashback, etc.)"
        )
        
        if uploaded_file is None:
            st.info("üëà Veuillez importer un fichier CSV pour commencer")
            st.stop()
        
        st.markdown("---")
        st.subheader("üìä Navigation")
        
        page_options = {
            "üéØ Objectifs du projet": page_objectifs,
            "üîç Exploration des donn√©es": page_eda,
            "üìä ACP sur les utilisateurs": page_acp,
            "üë• Segmentation KMeans": page_kmeans,
            "üö® Anomalies transactionnelles": page_anomalies,
            "ü§ñ Explications SHAP": page_xai
        }
        
        selected_page = st.radio(
            "S√©lectionnez une page",
            list(page_options.keys())
        )
    
    # Chargement des donn√©es
    df_raw, user_features, tx_features = load_and_prepare_data(uploaded_file)
    
    # Affichage des m√©triques dans la sidebar
    with st.sidebar:
        st.markdown("---")
        st.subheader("üìà Statistiques")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Transactions", df_raw.shape[0])
        with col2:
            st.metric("Utilisateurs", user_features.shape[0])
        
        st.metric("Features utilisateur", user_features.shape[1])
        st.metric("Features transaction", tx_features.shape[1])
    
    # Affichage de la page s√©lectionn√©e
    page_function = page_options[selected_page]
    
    if selected_page == "üéØ Objectifs du projet":
        page_function()
    elif selected_page == "üîç Exploration des donn√©es":
        page_function(df_raw, user_features, tx_features)
    elif selected_page == "üìä ACP sur les utilisateurs":
        page_function(user_features)
    elif selected_page == "üë• Segmentation KMeans":
        page_function(user_features)
    elif selected_page == "üö® Anomalies transactionnelles":
        page_function(df_raw, tx_features)
    elif selected_page == "ü§ñ Explications SHAP":
        page_function(df_raw, tx_features)


if __name__ == "__main__":
    main()