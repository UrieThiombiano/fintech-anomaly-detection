"""
Fonctions pour la d√©tection d'anomalies (Isolation Forest).
"""
import pandas as pd
import numpy as np
from typing import Dict, Tuple, List, Optional
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

from src.logging_config import get_logger
from src.utils import scale_features

logger = get_logger(__name__)


def train_isolation_forest(
    X: pd.DataFrame,
    contamination: float = 0.02,
    random_state: int = 42,
    n_estimators: int = 100
) -> Dict:
    """
    Entra√Æne un mod√®le Isolation Forest pour la d√©tection d'anomalies.
    """
    logger.info(f"Entra√Ænement Isolation Forest avec contamination={contamination}")
    
    # V√©rifier et nettoyer les donn√©es
    X_clean = prepare_data_for_anomaly_detection(X)
    
    # V√©rifier qu'il y a assez de donn√©es
    if len(X_clean) < 10:
        raise ValueError(f"Pas assez de donn√©es pour Isolation Forest: {len(X_clean)} √©chantillons")
    
    # Standardisation
    try:
        X_scaled, scaler, _ = scale_features(X_clean)
        logger.info(f"Donn√©es standardis√©es: shape={X_scaled.shape}")
    except Exception as e:
        logger.error(f"Erreur lors de la standardisation: {e}")
        # Fallback: simple normalisation
        X_scaled = X_clean.values.astype(float)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_scaled)
    
    # Isolation Forest avec gestion d'erreurs
    try:
        iforest = IsolationForest(
            contamination=min(contamination, 0.5),  # Limiter √† 50% max
            random_state=random_state,
            n_estimators=n_estimators,
            n_jobs=-1,
            verbose=0
        )
        
        # Pr√©dictions
        iforest.fit(X_scaled)
        anomaly_scores = iforest.decision_function(X_scaled)
        is_anomaly = iforest.predict(X_scaled)
        
    except Exception as e:
        logger.error(f"Erreur lors de l'entra√Ænement Isolation Forest: {e}")
        # Fallback: scores bas√©s sur la distance au centre
        from scipy.spatial.distance import mahalanobis
        center = np.mean(X_scaled, axis=0)
        cov = np.cov(X_scaled.T)
        try:
            inv_cov = np.linalg.inv(cov)
            anomaly_scores = np.array([mahalanobis(x, center, inv_cov) for x in X_scaled])
        except:
            # Simple distance euclidienne
            anomaly_scores = np.sqrt(np.sum((X_scaled - center) ** 2, axis=1))
        
        # D√©terminer les anomalies bas√©es sur un seuil
        threshold = np.percentile(anomaly_scores, 100 * (1 - contamination))
        is_anomaly = np.where(anomaly_scores > threshold, -1, 1)
        
        # Cr√©er un dummy iforest
        iforest = IsolationForest()
    
    # Convertir -1/1 en bool√©en (True=anomalie)
    is_anomaly_bool = (is_anomaly == -1)
    
    # Normaliser les scores pour avoir des valeurs positives (plus √©lev√© = plus anormal)
    normalized_scores = -anomaly_scores  # Inverser pour avoir positif = anormal
    
    result = {
        'scaler': scaler,
        'iforest': iforest,
        'anomaly_scores': normalized_scores,
        'is_anomaly': is_anomaly_bool,
        'contamination': contamination,
        'X_scaled': X_scaled,
        'X_clean': X_clean
    }
    
    n_anomalies = is_anomaly_bool.sum()
    logger.info(f"Isolation Forest entra√Æn√©: {n_anomalies} anomalies d√©tect√©es "
               f"({n_anomalies/len(X_clean)*100:.1f}%)")
    
    return result


def prepare_data_for_anomaly_detection(X: pd.DataFrame) -> pd.DataFrame:
    """
    Pr√©pare les donn√©es pour la d√©tection d'anomalies.
    
    Returns:
        DataFrame 100% num√©rique
    """
    X_clean = X.copy()
    
    # 1. Supprimer les colonnes avec toutes les valeurs manquantes
    X_clean = X_clean.dropna(axis=1, how='all')
    
    # 2. Supprimer les colonnes non-num√©riques
    non_numeric_cols = X_clean.select_dtypes(exclude=[np.number]).columns.tolist()
    if non_numeric_cols:
        logger.warning(f"Suppression des colonnes non-num√©riques: {non_numeric_cols}")
        X_clean = X_clean.drop(columns=non_numeric_cols)
    
    # 3. V√©rifier qu'il reste des colonnes
    if X_clean.shape[1] == 0:
        raise ValueError("Aucune colonne num√©rique disponible pour la d√©tection d'anomalies")
    
    # 4. Remplir les valeurs manquantes
    numeric_cols = X_clean.select_dtypes(include=[np.number]).columns
    if not numeric_cols.empty:
        # Remplacer inf/-inf d'abord
        X_clean = X_clean.replace([np.inf, -np.inf], np.nan)
        # Remplir avec la m√©diane
        X_clean[numeric_cols] = X_clean[numeric_cols].fillna(X_clean[numeric_cols].median())
    
    # 5. V√©rifier les dimensions finales
    logger.info(f"Donn√©es pr√©par√©es pour anomalie: {X_clean.shape}")
    
    return X_clean


def analyze_anomalies(
    original_df: pd.DataFrame,
    anomaly_result: Dict,
    score_threshold: Optional[float] = None
) -> pd.DataFrame:
    """
    Analyse les anomalies d√©tect√©es et les enrichit avec les donn√©es originales.
    """
    # Cr√©er une copie
    df_anomalies = original_df.copy()
    
    # S'assurer que les arrays ont la m√™me longueur
    n_original = len(df_anomalies)
    n_scores = len(anomaly_result['anomaly_scores'])
    
    if n_original != n_scores:
        logger.warning(f"Dimensions incompatibles: original={n_original}, scores={n_scores}")
        # Truncater ou pad les scores
        if n_scores < n_original:
            # R√©p√©ter les scores si moins nombreux
            repeat_factor = n_original // n_scores + 1
            scores = np.tile(anomaly_result['anomaly_scores'], repeat_factor)[:n_original]
            is_anomaly = np.tile(anomaly_result['is_anomaly'], repeat_factor)[:n_original]
        else:
            # Tronquer si plus nombreux
            scores = anomaly_result['anomaly_scores'][:n_original]
            is_anomaly = anomaly_result['is_anomaly'][:n_original]
    else:
        scores = anomaly_result['anomaly_scores']
        is_anomaly = anomaly_result['is_anomaly']
    
    df_anomalies['anomaly_score'] = scores
    df_anomalies['is_anomaly'] = is_anomaly
    
    # Filtrer par seuil si sp√©cifi√©
    if score_threshold is not None:
        df_anomalies['is_above_threshold'] = df_anomalies['anomaly_score'] >= score_threshold
    else:
        # Utiliser le 95√®me percentile comme seuil par d√©faut
        threshold = np.percentile(df_anomalies['anomaly_score'], 95)
        df_anomalies['is_above_threshold'] = df_anomalies['anomaly_score'] >= threshold
    
    # Trier par score d'anomalie
    df_anomalies = df_anomalies.sort_values('anomaly_score', ascending=False)
    
    return df_anomalies


def get_anomaly_statistics(anomaly_result: Dict) -> Dict:
    """
    Calcule des statistiques sur les anomalies d√©tect√©es.
    """
    scores = anomaly_result['anomaly_scores']
    is_anomaly = anomaly_result['is_anomaly']
    
    if len(scores) == 0:
        return {}
    
    stats = {
        'n_total': len(scores),
        'n_anomalies': is_anomaly.sum(),
        'pct_anomalies': is_anomaly.sum() / len(scores) * 100 if len(scores) > 0 else 0,
        'score_mean': float(scores.mean()) if len(scores) > 0 else 0,
        'score_std': float(scores.std()) if len(scores) > 0 else 0,
        'score_min': float(scores.min()) if len(scores) > 0 else 0,
        'score_max': float(scores.max()) if len(scores) > 0 else 0,
        'score_median': float(np.median(scores)) if len(scores) > 0 else 0,
        'score_q25': float(np.percentile(scores, 25)) if len(scores) > 0 else 0,
        'score_q75': float(np.percentile(scores, 75)) if len(scores) > 0 else 0,
        'score_q95': float(np.percentile(scores, 95)) if len(scores) > 0 else 0,
        'score_q99': float(np.percentile(scores, 99)) if len(scores) > 0 else 0
    }
    
    return {k: round(v, 4) if isinstance(v, float) else v for k, v in stats.items()}


def suggest_contamination(
    X: pd.DataFrame,
    percentiles: List[float] = None
) -> float:
    """
    Sugg√®re une valeur de contamination bas√©e sur les outliers statistiques.
    """
    if percentiles is None:
        percentiles = [95, 97.5, 99, 99.5]
    
    try:
        # Pr√©parer les donn√©es
        X_clean = prepare_data_for_anomaly_detection(X)
        
        # Standardisation
        X_scaled, _, _ = scale_features(X_clean)
        
        # Distances au centre (simplifi√©)
        distances = np.sqrt(np.sum(X_scaled**2, axis=1))
        
        # Pourcentage de points au-del√† de diff√©rents seuils
        suggestions = {}
        for p in percentiles:
            threshold = np.percentile(distances, p)
            pct_outliers = (distances > threshold).sum() / len(distances)
            suggestions[p] = round(pct_outliers, 4)
        
        # Retourner la moyenne des suggestions
        suggested_contamination = np.mean(list(suggestions.values()))
        
        logger.info(f"Contamination sugg√©r√©e: {suggested_contamination:.4f}")
        
        return min(max(suggested_contamination, 0.001), 0.1)  # Born√© entre 0.1% et 10%
    
    except Exception as e:
        logger.warning(f"Erreur dans suggest_contamination: {e}")
        # Valeur par d√©faut raisonnable
        return 0.02
    
    def generate_anomaly_report(
    df_raw: pd.DataFrame,
    anomaly_result: Dict,
    score_threshold: float = None
) -> str:
        """
        G√©n√®re un rapport d√©taill√© en fran√ßais des anomalies d√©tect√©es.
        
        Returns:
            Rapport format√© en markdown
        """
    if score_threshold is None:
        score_threshold = np.percentile(anomaly_result['anomaly_scores'], 95)
    
    df_anomalies = analyze_anomalies(df_raw, anomaly_result, score_threshold)
    high_score_tx = df_anomalies[df_anomalies['is_above_threshold']]
    
    stats = get_anomaly_statistics(anomaly_result)
    
    report = f"""
# üìä RAPPORT DE D√âTECTION D'ANOMALIES
*G√©n√©r√© le {pd.Timestamp.now().strftime('%d/%m/%Y √† %H:%M')}*

## üìà R√©sum√© ex√©cutif

### Donn√©es analys√©es
- **Transactions totales** : {stats['n_total']:,}
- **Features utilis√©es** : {anomaly_result['X_scaled'].shape[1]}
- **P√©riode analys√©e** : {df_raw['transaction_date'].min().date() if 'transaction_date' in df_raw.columns else 'Non sp√©cifi√©e'} au {df_raw['transaction_date'].max().date() if 'transaction_date' in df_raw.columns else 'Non sp√©cifi√©e'}

### R√©sultats de d√©tection
- **Anomalies d√©tect√©es** : {stats['n_anomalies']:,} ({stats['pct_anomalies']:.1f}%)
- **Score d'anomalie moyen** : {stats['score_mean']:.3f}
- **Score maximum** : {stats['score_max']:.3f}
- **Seuil de d√©tection (Q95)** : {stats['score_q95']:.3f}
- **Transactions au-dessus du seuil** : {len(high_score_tx):,}

## üîç Analyse des anomalies

### Top 5 transactions les plus suspectes
"""
    
    if not high_score_tx.empty:
        top5 = high_score_tx.head(5)
        for i, (idx, row) in enumerate(top5.iterrows(), 1):
            report += f"\n{i}. **Transaction {row.get('transaction_id', idx)}** : "
            report += f"Score = {row.get('anomaly_score', 0):.3f}, "
            if 'product_amount' in row:
                report += f"Montant = {row['product_amount']:.2f}‚Ç¨"
            if 'product_category' in row:
                report += f", Cat√©gorie = {row['product_category']}"
            report += f", User = {row.get('user_id', 'N/A')}"
    
    report += """

## üìä Distribution statistique

### Quartiles des scores
- **Q25 (25%)** : {:.3f}
- **Q50 (M√©diane)** : {:.3f}
- **Q75 (75%)** : {:.3f}
- **Q95 (95%)** : {:.3f}
- **Q99 (99%)** : {:.3f}

## üéØ Recommandations

1. **V√©rification manuelle** des transactions avec score > {:.3f}
2. **Analyse approfondie** des utilisateurs r√©currents dans les anomalies
3. **R√©vision des r√®gles m√©tier** pour les cat√©gories √† risque
4. **Surveillance continue** avec mise √† jour hebdomadaire du mod√®le

## üìà M√©triques de qualit√©

- **S√©paration scores** : {:.2%} (√©cart moyen normal/anomalie)
- **Stabilit√© d√©tection** : Contamination utilis√©e = {:.1%}
- **Capacit√© pr√©dictive** : Mod√®le entra√Æn√© sur {:,} √©chantillons

---
*Ce rapport a √©t√© g√©n√©r√© automatiquement par le syst√®me de d√©tection d'anomalies Fintech*
""".format(
        stats['score_q25'],
        stats['score_median'],
        stats['score_q75'],
        stats['score_q95'],
        stats['score_q99'],
        score_threshold,
        (stats['score_mean'] - np.mean(anomaly_result['anomaly_scores'][~anomaly_result['is_anomaly']])) / stats['score_mean'] if 'score_mean' in stats else 0,
        anomaly_result.get('contamination', 0.02),
        len(anomaly_result['anomaly_scores'])
    )
    
    return report